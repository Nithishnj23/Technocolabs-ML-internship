{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**This notebook is an exercise in the [Data Cleaning](https://www.kaggle.com/learn/data-cleaning) course.  You can reference the tutorial at [this link](https://www.kaggle.com/alexisbcook/parsing-dates).**\n\n---\n","metadata":{}},{"cell_type":"markdown","source":"In this exercise, you'll apply what you learned in the **Parsing dates** tutorial.\n\n# Setup\n\nThe questions below will give you feedback on your work. Run the following cell to set up the feedback system.","metadata":{}},{"cell_type":"code","source":"from learntools.core import binder\nbinder.bind(globals())\nfrom learntools.data_cleaning.ex3 import *\nprint(\"Setup Complete\")","metadata":{"execution":{"iopub.status.busy":"2022-05-25T17:31:18.504581Z","iopub.execute_input":"2022-05-25T17:31:18.505484Z","iopub.status.idle":"2022-05-25T17:31:18.511248Z","shell.execute_reply.started":"2022-05-25T17:31:18.505437Z","shell.execute_reply":"2022-05-25T17:31:18.510133Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stdout","text":"Setup Complete\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Get our environment set up\n\nThe first thing we'll need to do is load in the libraries and dataset we'll be using. We'll be working with a dataset containing information on earthquakes that occured between 1965 and 2016.","metadata":{}},{"cell_type":"code","source":"# modules we'll use\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport datetime\n\n# read in our data\nearthquakes = pd.read_csv(\"../input/earthquake-database/database.csv\")\n\n# set seed for reproducibility\nnp.random.seed(0)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T17:31:18.565203Z","iopub.execute_input":"2022-05-25T17:31:18.565570Z","iopub.status.idle":"2022-05-25T17:31:18.660983Z","shell.execute_reply.started":"2022-05-25T17:31:18.565540Z","shell.execute_reply":"2022-05-25T17:31:18.659946Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"markdown","source":"# 1) Check the data type of our date column\n\nYou'll be working with the \"Date\" column from the `earthquakes` dataframe.  Investigate this column now: does it look like it contains dates?  What is the dtype of the column?","metadata":{}},{"cell_type":"code","source":"# TODO: Your code here!\nearthquakes['Date'].dtype","metadata":{"execution":{"iopub.status.busy":"2022-05-25T17:31:18.662810Z","iopub.execute_input":"2022-05-25T17:31:18.663360Z","iopub.status.idle":"2022-05-25T17:31:18.670799Z","shell.execute_reply.started":"2022-05-25T17:31:18.663307Z","shell.execute_reply":"2022-05-25T17:31:18.669862Z"},"trusted":true},"execution_count":69,"outputs":[{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"dtype('O')"},"metadata":{}}]},{"cell_type":"markdown","source":"Once you have answered the question above, run the code cell below to get credit for your work.","metadata":{}},{"cell_type":"code","source":"# Check your answer (Run this code cell to receive credit!)\nprint(earthquakes['Date'].head())\n","metadata":{"execution":{"iopub.status.busy":"2022-05-25T17:31:18.704869Z","iopub.execute_input":"2022-05-25T17:31:18.705436Z","iopub.status.idle":"2022-05-25T17:31:18.712425Z","shell.execute_reply.started":"2022-05-25T17:31:18.705387Z","shell.execute_reply":"2022-05-25T17:31:18.711560Z"},"trusted":true},"execution_count":70,"outputs":[{"name":"stdout","text":"0    01/02/1965\n1    01/04/1965\n2    01/05/1965\n3    01/08/1965\n4    01/09/1965\nName: Date, dtype: object\n","output_type":"stream"}]},{"cell_type":"code","source":"# Line below will give you a hint\nq1.hint()","metadata":{"execution":{"iopub.status.busy":"2022-05-25T17:31:18.733723Z","iopub.execute_input":"2022-05-25T17:31:18.734715Z","iopub.status.idle":"2022-05-25T17:31:18.741166Z","shell.execute_reply.started":"2022-05-25T17:31:18.734673Z","shell.execute_reply":"2022-05-25T17:31:18.740473Z"},"trusted":true},"execution_count":71,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 2, \"questionType\": 4, \"questionId\": \"1_CheckDtype\", \"learnToolsVersion\": \"0.3.4\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Hint: Use `earthquakes['Date'].head()` to check that the column contains dates and verify that it has dtype \"object\".  You can also use `earthquakes['Date'].dtype` to verify the dtype.","text/markdown":"<span style=\"color:#3366cc\">Hint:</span> Use `earthquakes['Date'].head()` to check that the column contains dates and verify that it has dtype \"object\".  You can also use `earthquakes['Date'].dtype` to verify the dtype."},"metadata":{}}]},{"cell_type":"markdown","source":"# 2) Convert our date columns to datetime\n\nMost of the entries in the \"Date\" column follow the same format: \"month/day/four-digit year\".  However, the entry at index 3378 follows a completely different pattern.  Run the code cell below to see this.","metadata":{}},{"cell_type":"code","source":"earthquakes['date_parsed'] = pd.to_datetime(earthquakes ['Date'], format=\"%m/%d/%y\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"earthquakes['lenDate'] = earthquakes['Date'].apply(len)\nearthquakes.loc[earthquakes['lenDate'] > 10]","metadata":{"execution":{"iopub.status.busy":"2022-05-25T17:31:18.850152Z","iopub.status.idle":"2022-05-25T17:31:18.850985Z","shell.execute_reply.started":"2022-05-25T17:31:18.850753Z","shell.execute_reply":"2022-05-25T17:31:18.850797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"earthquakes.loc[3378, \"Date\"] = \"02/23/1975\"\nearthquakes.loc[7512, \"Date\"] = \"04/28/1986\"\nearthquakes.loc[20650, \"Date\"] = \"03/13/2011\"\nearthquakes.loc[3378, \"Date\"] = '02:58:41'\nearthquakes.loc[7512, \"Date\"] = '02:53:41'\nearthquakes.loc[20650, \"Date\"] = '02:23:34'\nearthquakes.loc[[3378, 7512, 20650]]","metadata":{"execution":{"iopub.status.busy":"2022-05-25T17:31:18.852116Z","iopub.status.idle":"2022-05-25T17:31:18.852694Z","shell.execute_reply.started":"2022-05-25T17:31:18.852493Z","shell.execute_reply":"2022-05-25T17:31:18.852516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"earthquakes['date_parsed'] = pd.to_datetime(earthquakes['Date'], format = \"%m/%d/%y\")","metadata":{"execution":{"iopub.status.busy":"2022-05-25T17:31:18.853819Z","iopub.status.idle":"2022-05-25T17:31:18.854393Z","shell.execute_reply.started":"2022-05-25T17:31:18.854184Z","shell.execute_reply":"2022-05-25T17:31:18.854208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"earthquakes['date_parsed'].head()","metadata":{"execution":{"iopub.status.busy":"2022-05-25T17:31:18.855438Z","iopub.status.idle":"2022-05-25T17:31:18.856014Z","shell.execute_reply.started":"2022-05-25T17:31:18.855816Z","shell.execute_reply":"2022-05-25T17:31:18.855841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This does appear to be an issue with data entry: ideally, all entries in the column have the same format.  We can get an idea of how widespread this issue is by checking the length of each entry in the \"Date\" column.","metadata":{}},{"cell_type":"code","source":"date_lengths = earthquakes.Date.str.len()\ndate_lengths.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-05-25T17:31:18.883766Z","iopub.execute_input":"2022-05-25T17:31:18.884442Z","iopub.status.idle":"2022-05-25T17:31:18.911692Z","shell.execute_reply.started":"2022-05-25T17:31:18.884393Z","shell.execute_reply":"2022-05-25T17:31:18.910533Z"},"trusted":true},"execution_count":73,"outputs":[{"execution_count":73,"output_type":"execute_result","data":{"text/plain":"10    23409\n24        3\nName: Date, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"Looks like there are two more rows that has a date in a different format.  Run the code cell below to obtain the indices corresponding to those rows and print the data.","metadata":{}},{"cell_type":"code","source":"indices = np.where([date_lengths == 24])[1]\nprint('Indices with corrupted data:', indices)\nearthquakes.loc[indices]","metadata":{"execution":{"iopub.status.busy":"2022-05-25T17:31:18.944432Z","iopub.execute_input":"2022-05-25T17:31:18.944925Z","iopub.status.idle":"2022-05-25T17:31:18.981949Z","shell.execute_reply.started":"2022-05-25T17:31:18.944883Z","shell.execute_reply":"2022-05-25T17:31:18.980840Z"},"trusted":true},"execution_count":74,"outputs":[{"name":"stdout","text":"Indices with corrupted data: [ 3378  7512 20650]\n","output_type":"stream"},{"execution_count":74,"output_type":"execute_result","data":{"text/plain":"                           Date                      Time  Latitude  \\\n3378   1975-02-23T02:58:41.000Z  1975-02-23T02:58:41.000Z     8.017   \n7512   1985-04-28T02:53:41.530Z  1985-04-28T02:53:41.530Z   -32.998   \n20650  2011-03-13T02:23:34.520Z  2011-03-13T02:23:34.520Z    36.344   \n\n       Longitude        Type  Depth  Depth Error  Depth Seismic Stations  \\\n3378     124.075  Earthquake  623.0          NaN                     NaN   \n7512     -71.766  Earthquake   33.0          NaN                     NaN   \n20650    142.344  Earthquake   10.1         13.9                   289.0   \n\n       Magnitude Magnitude Type  ...  Magnitude Seismic Stations  \\\n3378         5.6             MB  ...                         NaN   \n7512         5.6             MW  ...                         NaN   \n20650        5.8            MWC  ...                         NaN   \n\n       Azimuthal Gap  Horizontal Distance  Horizontal Error  Root Mean Square  \\\n3378             NaN                  NaN               NaN               NaN   \n7512             NaN                  NaN               NaN              1.30   \n20650           32.3                  NaN               NaN              1.06   \n\n               ID Source Location Source Magnitude Source    Status  \n3378   USP0000A09     US              US               US  Reviewed  \n7512   USP0002E81     US              US              HRV  Reviewed  \n20650  USP000HWQP     US              US             GCMT  Reviewed  \n\n[3 rows x 21 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Time</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>Type</th>\n      <th>Depth</th>\n      <th>Depth Error</th>\n      <th>Depth Seismic Stations</th>\n      <th>Magnitude</th>\n      <th>Magnitude Type</th>\n      <th>...</th>\n      <th>Magnitude Seismic Stations</th>\n      <th>Azimuthal Gap</th>\n      <th>Horizontal Distance</th>\n      <th>Horizontal Error</th>\n      <th>Root Mean Square</th>\n      <th>ID</th>\n      <th>Source</th>\n      <th>Location Source</th>\n      <th>Magnitude Source</th>\n      <th>Status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3378</th>\n      <td>1975-02-23T02:58:41.000Z</td>\n      <td>1975-02-23T02:58:41.000Z</td>\n      <td>8.017</td>\n      <td>124.075</td>\n      <td>Earthquake</td>\n      <td>623.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.6</td>\n      <td>MB</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>USP0000A09</td>\n      <td>US</td>\n      <td>US</td>\n      <td>US</td>\n      <td>Reviewed</td>\n    </tr>\n    <tr>\n      <th>7512</th>\n      <td>1985-04-28T02:53:41.530Z</td>\n      <td>1985-04-28T02:53:41.530Z</td>\n      <td>-32.998</td>\n      <td>-71.766</td>\n      <td>Earthquake</td>\n      <td>33.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.6</td>\n      <td>MW</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.30</td>\n      <td>USP0002E81</td>\n      <td>US</td>\n      <td>US</td>\n      <td>HRV</td>\n      <td>Reviewed</td>\n    </tr>\n    <tr>\n      <th>20650</th>\n      <td>2011-03-13T02:23:34.520Z</td>\n      <td>2011-03-13T02:23:34.520Z</td>\n      <td>36.344</td>\n      <td>142.344</td>\n      <td>Earthquake</td>\n      <td>10.1</td>\n      <td>13.9</td>\n      <td>289.0</td>\n      <td>5.8</td>\n      <td>MWC</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>32.3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.06</td>\n      <td>USP000HWQP</td>\n      <td>US</td>\n      <td>US</td>\n      <td>GCMT</td>\n      <td>Reviewed</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows Ã— 21 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Given all of this information, it's your turn to create a new column \"date_parsed\" in the `earthquakes` dataset that has correctly parsed dates in it.  \n\n**Note**: When completing this problem, you are allowed to (but are not required to) amend the entries in the \"Date\" and \"Time\" columns.  Do not remove any rows from the dataset.","metadata":{}},{"cell_type":"code","source":"earthquakes['date_parsed'] = pd.to_datetime(earthquakes['Date'], format=\"%m/%d/%y\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lines below will give you a hint or solution code\nq2.check()\nq2.hint()\nq2.solution()","metadata":{"execution":{"iopub.status.busy":"2022-05-25T17:31:19.044823Z","iopub.status.idle":"2022-05-25T17:31:19.045663Z","shell.execute_reply.started":"2022-05-25T17:31:19.045454Z","shell.execute_reply":"2022-05-25T17:31:19.045477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"earthquakes['lenDate'] = earthquakes['Date'].apply(len)\nearthquakes.loc[earthquakes['lenDate'] > 10]","metadata":{"execution":{"iopub.status.busy":"2022-05-25T17:31:19.046518Z","iopub.status.idle":"2022-05-25T17:31:19.047177Z","shell.execute_reply.started":"2022-05-25T17:31:19.046980Z","shell.execute_reply":"2022-05-25T17:31:19.047001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3) Select the day of the month\n\nCreate a Pandas Series `day_of_month_earthquakes` containing the day of the month from the \"date_parsed\" column.","metadata":{}},{"cell_type":"code","source":"# try to get the day of the month from the date column\nday_of_month_earthquakes = earthquakes['date_parsed'].dt.day\n\n\n# Check your answer\nq3.check()","metadata":{"execution":{"iopub.status.busy":"2022-05-25T17:31:19.047998Z","iopub.status.idle":"2022-05-25T17:31:19.048329Z","shell.execute_reply.started":"2022-05-25T17:31:19.048168Z","shell.execute_reply":"2022-05-25T17:31:19.048184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lines below will give you a hint or solution code\nq3.check()\nq3.hint()\nq3.solution()","metadata":{"execution":{"iopub.status.busy":"2022-05-25T17:31:19.049368Z","iopub.status.idle":"2022-05-25T17:31:19.049749Z","shell.execute_reply.started":"2022-05-25T17:31:19.049589Z","shell.execute_reply":"2022-05-25T17:31:19.049606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4) Plot the day of the month to check the date parsing\n\nPlot the days of the month from your earthquake dataset.","metadata":{}},{"cell_type":"code","source":"# TODO: Your code here!\nday_of_month_earthquakes = day_of_month_earthquakes.dropna()\nsns.distplot(day_of_month_earthquakes, kde=False, bins=31)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T17:31:19.050799Z","iopub.status.idle":"2022-05-25T17:31:19.051132Z","shell.execute_reply.started":"2022-05-25T17:31:19.050971Z","shell.execute_reply":"2022-05-25T17:31:19.050987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Does the graph make sense to you?","metadata":{}},{"cell_type":"code","source":"# Check your answer (Run this code cell to receive credit!)\nq4.check()","metadata":{"execution":{"iopub.status.busy":"2022-05-25T17:31:19.059869Z","iopub.execute_input":"2022-05-25T17:31:19.060239Z","iopub.status.idle":"2022-05-25T17:31:19.068894Z","shell.execute_reply.started":"2022-05-25T17:31:19.060209Z","shell.execute_reply":"2022-05-25T17:31:19.068059Z"},"trusted":true},"execution_count":76,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.25, \"interactionType\": 1, \"questionType\": 4, \"questionId\": \"4_PlotDayOfMonth\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Correct: \n\nThe graph should make sense: it shows a relatively even distribution in days of the month,which is what we would expect.","text/markdown":"<span style=\"color:#33cc33\">Correct:</span> \n\nThe graph should make sense: it shows a relatively even distribution in days of the month,which is what we would expect."},"metadata":{}}]},{"cell_type":"code","source":"# Line below will give you a hint\nq4.hint()","metadata":{"execution":{"iopub.status.busy":"2022-05-25T17:31:19.114119Z","iopub.execute_input":"2022-05-25T17:31:19.114666Z","iopub.status.idle":"2022-05-25T17:31:19.121680Z","shell.execute_reply.started":"2022-05-25T17:31:19.114635Z","shell.execute_reply":"2022-05-25T17:31:19.120830Z"},"trusted":true},"execution_count":77,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 2, \"questionType\": 4, \"questionId\": \"4_PlotDayOfMonth\", \"learnToolsVersion\": \"0.3.4\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Hint: \nRemove the missing values, and then use `sns.distplot()` as follows:\n\n```python\n# remove na's\nday_of_month_earthquakes = day_of_month_earthquakes.dropna()\n\n# plot the day of the month\nsns.distplot(day_of_month_earthquakes, kde=False, bins=31)\n```\n","text/markdown":"<span style=\"color:#3366cc\">Hint:</span> \nRemove the missing values, and then use `sns.distplot()` as follows:\n\n```python\n# remove na's\nday_of_month_earthquakes = day_of_month_earthquakes.dropna()\n\n# plot the day of the month\nsns.distplot(day_of_month_earthquakes, kde=False, bins=31)\n```\n\n"},"metadata":{}}]}]}